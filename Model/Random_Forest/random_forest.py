# -*- coding: utf-8 -*-
"""random_forest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i0M2pBg_ZA19x1Rg5_zg1wDWW8ofEw1r

Importing necessary libraries
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score

"""Reading the dataset with Pandas after mounting the dataset in google colab"""

#reading the dataset with a dataframe
df = pd.read_csv("final_preprocessed_dataset.csv")

#eye balling the data
df.head(5)

"""Converting the Apt Groups to numbers for running properly in the classifier model. This is our lablled column for using the supervised learning technique"""

df['APT Group'] = LabelEncoder().fit_transform(df['APT Group'])
df['APT Group'].max()
df.head(5)

"""Dropping resource column"""

df = df.drop('Resource', 1)

#eye balling information about our dataset
df.info()

"""Sklearn Train Test Split Method"""

#the labelled column is Apt Group and the rest is features
label = np.array(df['APT Group'])
features = df.drop('APT Group',1)

#choosing a 70-30 split to test out the performance
seed =50
X_train, X_test, y_train, y_test = train_test_split(features,label,test_size=0.30, random_state = seed)

X_train.dtypes

X_train

X_test.dtypes

X_test

"""Building the Random Forest Classifier"""

rf_classifier = RandomForestClassifier(
                      min_samples_leaf=50,
                      n_estimators=150,
                      bootstrap=True,
                      oob_score=True,
                      n_jobs=-1,
                      random_state=seed,
                      max_features='auto')

rf_classifier.fit(X_train,y_train)

y_pred = rf_classifier.predict(X_test)

print(y_pred)

"""Confusion Matrix"""

cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

"""# Observation:

Accuracy acquired about 75% accuracy. Needs more hyperparameter tuning to increase the accuracy. Maybe contributing other factors along the way too can lead to better accuracy.
"""